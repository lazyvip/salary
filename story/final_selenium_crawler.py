#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆç‰ˆSeleniumçˆ¬è™« - ä½¿ç”¨æœ€æ–°çš„webdriver-manager
å¤„ç†JavaScriptæ¸²æŸ“çš„æ•…äº‹ç½‘ç«™ï¼Œè‡ªåŠ¨åŒ¹é…Chromeç‰ˆæœ¬
"""

import time
import json
import sqlite3
import logging
import re
import os
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from bs4 import BeautifulSoup
from webdriver_manager.chrome import ChromeDriverManager

class FinalSeleniumCrawler:
    def __init__(self, headless=False):
        self.headless = headless
        self.base_url = "https://storynook.cn"
        self.stories = []
        self.failed_ids = []
        self.success_count = 0
        self.total_count = 0
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('final_selenium.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self.init_database()
        
    def create_driver(self):
        """åˆ›å»ºChrome WebDriverå®ä¾‹"""
        chrome_options = Options()
        
        if self.headless:
            chrome_options.add_argument('--headless')
        
        # ä¼˜åŒ–é€‰é¡¹
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # è®¾ç½®ç”¨æˆ·ä»£ç†
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        try:
            # ä½¿ç”¨webdriver-managerè‡ªåŠ¨ä¸‹è½½åŒ¹é…çš„ChromeDriver
            self.logger.info("æ­£åœ¨åˆå§‹åŒ–ChromeDriver...")
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # æ‰§è¡Œåæ£€æµ‹è„šæœ¬
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            self.logger.info("âœ… WebDriveråˆ›å»ºæˆåŠŸ")
            return driver
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºWebDriverå¤±è´¥: {e}")
            return None
    
    def init_database(self):
        """åˆå§‹åŒ–SQLiteæ•°æ®åº“"""
        self.conn = sqlite3.connect('final_selenium_stories.db', check_same_thread=False)
        self.cursor = self.conn.cursor()
        
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS stories (
                id INTEGER PRIMARY KEY,
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                category TEXT,
                word_count INTEGER,
                scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                url TEXT
            )
        ''')
        self.conn.commit()
        self.logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    
    def wait_for_content_load(self, driver, timeout=30):
        """ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½å®Œæˆ"""
        try:
            # ç­‰å¾…é¡µé¢åŸºæœ¬ç»“æ„åŠ è½½
            WebDriverWait(driver, timeout).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # ç­‰å¾…JavaScriptæ‰§è¡Œ
            self.logger.info("â³ ç­‰å¾…JavaScriptæ‰§è¡Œ...")
            time.sleep(8)  # ç­‰å¾…JavaScriptå®Œå…¨æ‰§è¡Œ
            
            # æ£€æŸ¥é¡µé¢åŠ è½½çŠ¶æ€
            try:
                ready_state = driver.execute_script("return document.readyState")
                self.logger.info(f"ğŸ“„ é¡µé¢çŠ¶æ€: {ready_state}")
                
                # ç­‰å¾…å¯èƒ½çš„åŠ¨æ€å†…å®¹åŠ è½½
                for i in range(3):
                    time.sleep(3)
                    current_length = len(driver.page_source)
                    self.logger.info(f"ğŸ“ é¡µé¢æºç é•¿åº¦: {current_length}")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ•…äº‹ç›¸å…³å†…å®¹
                    page_text = driver.execute_script("return document.body.innerText")
                    if 'æ•…äº‹' in page_text and len(page_text) > 500:
                        self.logger.info("âœ… æ£€æµ‹åˆ°æ•…äº‹å†…å®¹")
                        break
                
            except Exception as e:
                self.logger.debug(f"JavaScriptæ‰§è¡Œæ£€æŸ¥å¤±è´¥: {e}")
            
            return True
        except TimeoutException:
            self.logger.warning(f"âš ï¸ é¡µé¢åŠ è½½è¶…æ—¶: {driver.current_url}")
            return False
    
    def extract_story_content(self, driver, story_id):
        """ä»é¡µé¢ä¸­æå–æ•…äº‹å†…å®¹"""
        try:
            # ç­‰å¾…å†…å®¹åŠ è½½
            if not self.wait_for_content_load(driver):
                return None
            
            # è·å–é¡µé¢æºç 
            page_source = driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # ä¿å­˜è°ƒè¯•HTML
            with open(f'final_debug_{story_id}.html', 'w', encoding='utf-8') as f:
                f.write(page_source)
            
            self.logger.info(f"ğŸ“– é¡µé¢æ ‡é¢˜: {driver.title}")
            self.logger.info(f"ğŸ”— é¡µé¢URL: {driver.current_url}")
            self.logger.info(f"ğŸ“ é¡µé¢æºç é•¿åº¦: {len(page_source)}")
            
            # æ£€æŸ¥é¡µé¢æ˜¯å¦åŒ…å«æœ‰æ•ˆå†…å®¹
            page_text = soup.get_text()
            if '404' in page_text or 'Not Found' in page_text:
                self.logger.warning(f"âš ï¸ æ•…äº‹ {story_id} é¡µé¢è¿”å›404")
                return None
            
            # å°è¯•å¤šç§æ–¹å¼æå–æ ‡é¢˜
            title = None
            
            # 1. ä»é¡µé¢æ ‡é¢˜æå–
            page_title = driver.title.strip()
            if page_title and 'å°æ•…äº‹é“º' not in page_title and len(page_title) < 200:
                title = page_title
                self.logger.info(f"ğŸ“ ä»é¡µé¢æ ‡é¢˜æå–: {title}")
            
            # 2. ä½¿ç”¨JavaScriptæŸ¥æ‰¾æ ‡é¢˜
            if not title:
                try:
                    js_title = driver.execute_script("""
                        // æŸ¥æ‰¾å¯èƒ½çš„æ ‡é¢˜å…ƒç´ 
                        var titleSelectors = [
                            'h1', 'h2', 'h3', '.title', '.story-title', '.post-title',
                            '.article-title', '.content-title', '[class*="title"]',
                            '[id*="title"]', '.story-name', '.article-name'
                        ];
                        
                        for (var i = 0; i < titleSelectors.length; i++) {
                            var elements = document.querySelectorAll(titleSelectors[i]);
                            for (var j = 0; j < elements.length; j++) {
                                var text = elements[j].innerText || elements[j].textContent;
                                if (text && text.length > 2 && text.length < 200 && 
                                    !text.includes('å°æ•…äº‹é“º') && 
                                    !text.includes('é¦–é¡µ') &&
                                    !text.includes('å¯¼èˆª') &&
                                    !text.includes('èœå•')) {
                                    return text.trim();
                                }
                            }
                        }
                        return null;
                    """)
                    
                    if js_title:
                        title = js_title
                        self.logger.info(f"ğŸ” ä»JavaScriptæå–æ ‡é¢˜: {title}")
                except Exception as e:
                    self.logger.debug(f"JavaScriptæ ‡é¢˜æå–å¤±è´¥: {e}")
            
            # æå–å†…å®¹
            content = None
            
            # 1. ä½¿ç”¨JavaScriptæŸ¥æ‰¾å†…å®¹
            try:
                js_content = driver.execute_script("""
                    // æŸ¥æ‰¾å¯èƒ½åŒ…å«æ•…äº‹å†…å®¹çš„å…ƒç´ 
                    var contentSelectors = [
                        '.story-content', '.post-content', '.article-content',
                        '.content', '#content', 'article', '.main-content',
                        '.story-body', '.text-content', 'main', '.story-text',
                        '.article-body', '.post-body', '[class*="content"]',
                        '[id*="content"]', '.story-detail', '.article-detail'
                    ];
                    
                    for (var i = 0; i < contentSelectors.length; i++) {
                        var elements = document.querySelectorAll(contentSelectors[i]);
                        for (var j = 0; j < elements.length; j++) {
                            var text = elements[j].innerText || elements[j].textContent;
                            if (text && text.length > 200 && 
                                !text.includes('å°æ•…äº‹é“ºæ±‡é›†äº†å„ç§ç±»å‹') &&
                                !text.includes('ç‰ˆæƒæ‰€æœ‰') &&
                                !text.includes('è”ç³»æˆ‘ä»¬')) {
                                return text.trim();
                            }
                        }
                    }
                    
                    // å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾æœ€é•¿çš„æ–‡æœ¬å—
                    var allElements = document.querySelectorAll('div, p, section, article, span');
                    var longestText = '';
                    
                    for (var k = 0; k < allElements.length; k++) {
                        var element = allElements[k];
                        // è·³è¿‡å¯¼èˆªã€èœå•ç­‰å…ƒç´ 
                        if (element.className && (
                            element.className.includes('nav') ||
                            element.className.includes('menu') ||
                            element.className.includes('header') ||
                            element.className.includes('footer') ||
                            element.className.includes('sidebar')
                        )) {
                            continue;
                        }
                        
                        var text = element.innerText || element.textContent;
                        if (text && text.length > longestText.length && text.length > 200) {
                            longestText = text;
                        }
                    }
                    
                    return longestText || null;
                """)
                
                if js_content and len(js_content) > 200:
                    content = js_content
                    self.logger.info(f"ğŸ“„ ä»JavaScriptæå–å†…å®¹: {len(content)}å­—ç¬¦")
            except Exception as e:
                self.logger.debug(f"JavaScriptå†…å®¹æå–å¤±è´¥: {e}")
            
            # 2. ä»HTMLå…ƒç´ æå–ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰
            if not content:
                content_selectors = [
                    '.story-content', '.post-content', '.article-content',
                    '.content', '#content', 'article', '.main-content',
                    '.story-body', '.text-content', 'main', '.story-text',
                    '.article-body', '.post-body'
                ]
                
                for selector in content_selectors:
                    elements = soup.select(selector)
                    for elem in elements:
                        text = elem.get_text(strip=True)
                        if text and len(text) > 200 and 'å°æ•…äº‹é“ºæ±‡é›†äº†å„ç§ç±»å‹' not in text:
                            content = text
                            self.logger.info(f"ğŸ” ä»{selector}æå–å†…å®¹: {len(text)}å­—ç¬¦")
                            break
                    if content:
                        break
            
            # 3. ä»é¡µé¢æ‰€æœ‰æ–‡æœ¬ä¸­æå–æœ€é•¿çš„æ®µè½ï¼ˆæœ€åçš„å¤‡ç”¨æ–¹æ³•ï¼‰
            if not content:
                all_text = soup.get_text()
                paragraphs = [p.strip() for p in all_text.split('\n') if p.strip()]
                long_paragraphs = [p for p in paragraphs if len(p) > 200]
                if long_paragraphs:
                    content = max(long_paragraphs, key=len)
                    self.logger.info(f"ğŸ“ ä»æœ€é•¿æ®µè½æå–å†…å®¹: {len(content)}å­—ç¬¦")
            
            # éªŒè¯æå–çš„å†…å®¹
            if not title:
                title = f"æ•…äº‹ {story_id}"
            
            if not content or len(content) < 100:
                self.logger.warning(f"âš ï¸ æ•…äº‹ {story_id} å†…å®¹å¤ªçŸ­æˆ–ä¸ºç©º: {len(content) if content else 0}å­—ç¬¦")
                # ä¿å­˜é¡µé¢æˆªå›¾ç”¨äºè°ƒè¯•
                try:
                    driver.save_screenshot(f'final_debug_screenshot_{story_id}.png')
                    self.logger.info(f"ğŸ“¸ å·²ä¿å­˜è°ƒè¯•æˆªå›¾: final_debug_screenshot_{story_id}.png")
                except:
                    pass
                return None
            
            # æ¸…ç†å†…å®¹
            content = re.sub(r'\s+', ' ', content).strip()
            
            # æ¨æ–­åˆ†ç±»
            category = self.infer_category(title, content)
            
            # è®¡ç®—å­—æ•°
            word_count = len(content)
            
            story_data = {
                'id': story_id,
                'title': title,
                'content': content,
                'category': category,
                'word_count': word_count,
                'url': driver.current_url
            }
            
            self.logger.info(f"âœ… æˆåŠŸæå–æ•…äº‹ {story_id}: {title[:50]}... (å­—æ•°: {word_count})")
            return story_data
            
        except Exception as e:
            self.logger.error(f"âŒ æå–æ•…äº‹ {story_id} å†…å®¹å¤±è´¥: {e}")
            return None
    
    def infer_category(self, title, content):
        """æ ¹æ®æ ‡é¢˜å’Œå†…å®¹æ¨æ–­æ•…äº‹åˆ†ç±»"""
        categories = {
            'çˆ±æƒ…æ•…äº‹': ['çˆ±æƒ…', 'æ‹çˆ±', 'æƒ…ä¾£', 'ç”·å‹', 'å¥³å‹', 'ç»“å©š', 'å©šå§»', 'æµªæ¼«', 'çº¦ä¼š', 'è¡¨ç™½'],
            'ææ€–æ•…äº‹': ['ææ€–', 'é¬¼', 'çµå¼‚', 'æƒŠæ‚š', 'å¯æ€•', 'é˜´æ£®', 'è¯¡å¼‚', 'è¡€è…¥', 'æ­»äº¡'],
            'åŠ±å¿—æ•…äº‹': ['åŠ±å¿—', 'æˆåŠŸ', 'å¥‹æ–—', 'åšæŒ', 'æ¢¦æƒ³', 'åŠªåŠ›', 'æ‹¼æ', 'æˆé•¿', 'è¿›æ­¥'],
            'å„¿ç«¥æ•…äº‹': ['å°æœ‹å‹', 'å­©å­', 'ç«¥è¯', 'åŠ¨ç‰©', 'æ£®æ—', 'ç‹å­', 'å…¬ä¸»', 'å°ç†Š', 'å°å…”'],
            'å†å²æ•…äº‹': ['å¤ä»£', 'å†å²', 'æœä»£', 'çš‡å¸', 'å°†å†›', 'æˆ˜äº‰', 'ä¼ è¯´', 'å¤æ—¶'],
            'ç¥è¯æ•…äº‹': ['ç¥è¯', 'ä»™äºº', 'ç¥ä»™', 'é¾™', 'å‡¤å‡°', 'ä¼ è¯´', 'ç¥', 'ä»™å¥³', 'å¤©å®«'],
            'å¯“è¨€æ•…äº‹': ['å¯“è¨€', 'é“ç†', 'å¯ç¤º', 'æ™ºæ…§', 'å“²ç†', 'æ•™è®­', 'æ˜ç™½'],
            'æ°‘é—´æ•…äº‹': ['æ°‘é—´', 'ä¼ è¯´', 'è€äºº', 'æ‘åº„', 'ä¹¡æ‘', 'å†œå¤«', 'è€å¥¶å¥¶'],
            'ç§‘å¹»æ•…äº‹': ['ç§‘å¹»', 'æœªæ¥', 'æœºå™¨äºº', 'å¤ªç©º', 'å¤–æ˜Ÿäºº', 'ç§‘æŠ€', 'å®‡å®™'],
            'æ‚¬ç–‘æ•…äº‹': ['æ‚¬ç–‘', 'æ¨ç†', 'ä¾¦æ¢', 'è°œå›¢', 'ç ´æ¡ˆ', 'çº¿ç´¢', 'è°ƒæŸ¥', 'çœŸç›¸']
        }
        
        text = (title + ' ' + content).lower()
        
        for category, keywords in categories.items():
            if any(keyword in text for keyword in keywords):
                return category
        
        return 'å…¶ä»–æ•…äº‹'
    
    def crawl_single_story(self, story_id):
        """çˆ¬å–å•ä¸ªæ•…äº‹"""
        driver = None
        try:
            driver = self.create_driver()
            if not driver:
                self.logger.error(f"âŒ æ— æ³•åˆ›å»ºWebDriverï¼Œè·³è¿‡æ•…äº‹ {story_id}")
                return None
            
            url = f"{self.base_url}/story/{story_id}"
            self.logger.info(f"ğŸ” æ­£åœ¨çˆ¬å–æ•…äº‹ {story_id}: {url}")
            
            driver.get(url)
            
            story_data = self.extract_story_content(driver, story_id)
            
            if story_data:
                # ä¿å­˜åˆ°æ•°æ®åº“
                self.save_story_to_db(story_data)
                return story_data
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ çˆ¬å–æ•…äº‹ {story_id} å¤±è´¥: {e}")
            return None
        finally:
            if driver:
                driver.quit()
    
    def save_story_to_db(self, story_data):
        """ä¿å­˜æ•…äº‹åˆ°æ•°æ®åº“"""
        try:
            self.cursor.execute('''
                INSERT OR REPLACE INTO stories 
                (id, title, content, category, word_count, url)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                story_data['id'],
                story_data['title'],
                story_data['content'],
                story_data['category'],
                story_data['word_count'],
                story_data['url']
            ))
            self.conn.commit()
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æ•…äº‹åˆ°æ•°æ®åº“å¤±è´¥: {e}")
    
    def crawl_stories(self, start_id=1, end_id=5):
        """æ‰¹é‡çˆ¬å–æ•…äº‹ï¼ˆå•çº¿ç¨‹ï¼‰"""
        self.logger.info(f"ğŸš€ å¼€å§‹çˆ¬å–æ•…äº‹ {start_id} åˆ° {end_id}")
        self.total_count = end_id - start_id + 1
        
        for story_id in range(start_id, end_id + 1):
            try:
                result = self.crawl_single_story(story_id)
                if result:
                    self.stories.append(result)
                    self.success_count += 1
                    self.logger.info(f"âœ… æ•…äº‹ {story_id} çˆ¬å–æˆåŠŸ ({self.success_count}/{self.total_count})")
                else:
                    self.failed_ids.append(story_id)
                    self.logger.warning(f"âŒ æ•…äº‹ {story_id} çˆ¬å–å¤±è´¥")
                    
                # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                time.sleep(3)
                
            except Exception as e:
                self.failed_ids.append(story_id)
                self.logger.error(f"âŒ æ•…äº‹ {story_id} å¤„ç†å¼‚å¸¸: {e}")
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
    
    def generate_report(self):
        """ç”Ÿæˆçˆ¬å–æŠ¥å‘Š"""
        success_rate = (self.success_count / self.total_count) * 100 if self.total_count > 0 else 0
        
        report = {
            'crawl_time': datetime.now().isoformat(),
            'total_stories': self.total_count,
            'successful_stories': self.success_count,
            'failed_stories': len(self.failed_ids),
            'success_rate': f"{success_rate:.2f}%",
            'failed_ids': self.failed_ids,
            'stories_sample': self.stories  # ä¿å­˜æ‰€æœ‰æ•…äº‹
        }
        
        # ä¿å­˜JSONæŠ¥å‘Š
        with open('final_selenium_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜æ‰€æœ‰æ•…äº‹åˆ°JSON
        with open('final_selenium_stories.json', 'w', encoding='utf-8') as f:
            json.dump(self.stories, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"""
=== ğŸ‰ çˆ¬å–å®Œæˆ ===
æ€»è®¡æ•…äº‹: {self.total_count}
æˆåŠŸçˆ¬å–: {self.success_count}
å¤±è´¥æ•°é‡: {len(self.failed_ids)}
æˆåŠŸç‡: {success_rate:.2f}%
æŠ¥å‘Šå·²ä¿å­˜åˆ°: final_selenium_report.json
æ•…äº‹æ•°æ®å·²ä¿å­˜åˆ°: final_selenium_stories.json
æ•°æ®åº“: final_selenium_stories.db
        """)
    
    def analyze_content_uniqueness(self):
        """åˆ†æå†…å®¹å”¯ä¸€æ€§"""
        if not self.stories:
            self.logger.warning("âš ï¸ æ²¡æœ‰æ•…äº‹æ•°æ®å¯åˆ†æ")
            return
        
        # ç»Ÿè®¡å”¯ä¸€æ ‡é¢˜å’Œå†…å®¹
        unique_titles = set()
        unique_contents = set()
        content_groups = {}
        category_count = {}
        
        for story in self.stories:
            title = story['title']
            content = story['content']
            category = story['category']
            
            unique_titles.add(title)
            unique_contents.add(content)
            
            # æŒ‰å†…å®¹åˆ†ç»„
            if content not in content_groups:
                content_groups[content] = []
            content_groups[content].append(story['id'])
            
            # ç»Ÿè®¡åˆ†ç±»
            category_count[category] = category_count.get(category, 0) + 1
        
        # æ‰¾å‡ºé‡å¤å†…å®¹
        duplicate_groups = {content: ids for content, ids in content_groups.items() if len(ids) > 1}
        
        analysis = {
            'total_stories': len(self.stories),
            'unique_titles': len(unique_titles),
            'unique_contents': len(unique_contents),
            'duplicate_content_groups': len(duplicate_groups),
            'duplicate_story_count': sum(len(ids) for ids in duplicate_groups.values()),
            'category_distribution': category_count,
            'sample_stories': [
                {
                    'id': story['id'],
                    'title': story['title'][:100],
                    'content_preview': story['content'][:300] + '...',
                    'category': story['category'],
                    'word_count': story['word_count']
                }
                for story in self.stories
            ]
        }
        
        self.logger.info(f"""
=== ğŸ“Š å†…å®¹å”¯ä¸€æ€§åˆ†æ ===
æ€»æ•…äº‹æ•°: {analysis['total_stories']}
å”¯ä¸€æ ‡é¢˜æ•°: {analysis['unique_titles']}
å”¯ä¸€å†…å®¹æ•°: {analysis['unique_contents']}
é‡å¤å†…å®¹ç»„æ•°: {analysis['duplicate_content_groups']}
é‡å¤æ•…äº‹æ€»æ•°: {analysis['duplicate_story_count']}
åˆ†ç±»åˆ†å¸ƒ: {analysis['category_distribution']}
        """)
        
        # ä¿å­˜åˆ†æç»“æœ
        with open('final_selenium_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)
        
        return analysis
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if hasattr(self, 'conn'):
            self.conn.close()

def main():
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler = FinalSeleniumCrawler(headless=False)  # éæ— å¤´æ¨¡å¼ä¾¿äºè§‚å¯Ÿ
    
    try:
        # çˆ¬å–å‰5ä¸ªæ•…äº‹è¿›è¡Œæµ‹è¯•
        crawler.crawl_stories(start_id=1, end_id=5)
        
        # åˆ†æå†…å®¹å”¯ä¸€æ€§
        crawler.analyze_content_uniqueness()
        
    except KeyboardInterrupt:
        crawler.logger.info("âš ï¸ ç”¨æˆ·ä¸­æ–­çˆ¬å–")
    except Exception as e:
        crawler.logger.error(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        crawler.close()

if __name__ == "__main__":
    main()