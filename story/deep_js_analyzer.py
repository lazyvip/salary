#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±åº¦JavaScriptåˆ†æå™¨
ä¸“é—¨åˆ†æç½‘ç«™çš„JavaScriptä»£ç å’ŒAJAXè¯·æ±‚
"""

import time
import json
import logging
import os
import re
import requests
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
from bs4 import BeautifulSoup

class DeepJSAnalyzer:
    def __init__(self):
        self.base_url = "https://storynook.cn"
        self.chromedriver_path = os.path.join(os.path.dirname(__file__), 'chromedriver_exe', 'chromedriver.exe')
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('deep_js_analyzer.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # éªŒè¯ChromeDriver
        if not os.path.exists(self.chromedriver_path):
            raise FileNotFoundError(f"ChromeDriveræœªæ‰¾åˆ°: {self.chromedriver_path}")
    
    def create_driver(self):
        """åˆ›å»ºChrome WebDriver"""
        chrome_options = Options()
        
        # åŸºæœ¬é€‰é¡¹
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # å¯ç”¨ç½‘ç»œæ—¥å¿—
        chrome_options.add_argument('--enable-logging')
        chrome_options.add_argument('--log-level=0')
        chrome_options.set_capability('goog:loggingPrefs', {'performance': 'ALL'})
        
        # è®¾ç½®ç”¨æˆ·ä»£ç†
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        try:
            service = Service(self.chromedriver_path)
            driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # åæ£€æµ‹
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            self.logger.info("âœ… WebDriveråˆ›å»ºæˆåŠŸ")
            return driver
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºWebDriverå¤±è´¥: {e}")
            return None
    
    def download_and_analyze_js(self):
        """ä¸‹è½½å¹¶åˆ†æJavaScriptæ–‡ä»¶"""
        js_files = [
            "https://storynook.cn/js/supabase-client.js",
            "https://storynook.cn/js/app.js"
        ]
        
        analysis_results = {}
        
        for js_url in js_files:
            try:
                self.logger.info(f"ğŸ“¥ ä¸‹è½½JavaScriptæ–‡ä»¶: {js_url}")
                
                response = requests.get(js_url, timeout=10)
                response.raise_for_status()
                
                js_content = response.text
                filename = os.path.basename(js_url)
                
                # ä¿å­˜JSæ–‡ä»¶
                with open(f"downloaded_{filename}", 'w', encoding='utf-8') as f:
                    f.write(js_content)
                
                # åˆ†æJSå†…å®¹
                analysis = self.analyze_js_content(js_content, filename)
                analysis_results[filename] = analysis
                
                self.logger.info(f"âœ… åˆ†æå®Œæˆ: {filename}")
                
            except Exception as e:
                self.logger.error(f"âŒ ä¸‹è½½/åˆ†æ {js_url} å¤±è´¥: {e}")
                analysis_results[os.path.basename(js_url)] = {'error': str(e)}
        
        return analysis_results
    
    def analyze_js_content(self, js_content, filename):
        """åˆ†æJavaScriptå†…å®¹"""
        analysis = {
            'file_size': len(js_content),
            'functions': [],
            'ajax_calls': [],
            'api_endpoints': [],
            'story_related': [],
            'routing_logic': [],
            'database_operations': []
        }
        
        # æŸ¥æ‰¾å‡½æ•°å®šä¹‰
        function_patterns = [
            r'function\s+(\w+)\s*\(',
            r'(\w+)\s*:\s*function\s*\(',
            r'const\s+(\w+)\s*=\s*\(',
            r'let\s+(\w+)\s*=\s*\(',
            r'var\s+(\w+)\s*=\s*function'
        ]
        
        for pattern in function_patterns:
            matches = re.findall(pattern, js_content, re.IGNORECASE)
            analysis['functions'].extend(matches)
        
        # æŸ¥æ‰¾AJAXè°ƒç”¨
        ajax_patterns = [
            r'\.ajax\s*\(',
            r'fetch\s*\(',
            r'XMLHttpRequest',
            r'\.get\s*\(',
            r'\.post\s*\(',
            r'\.put\s*\(',
            r'\.delete\s*\('
        ]
        
        for pattern in ajax_patterns:
            matches = re.findall(pattern, js_content, re.IGNORECASE)
            if matches:
                analysis['ajax_calls'].extend(matches)
        
        # æŸ¥æ‰¾APIç«¯ç‚¹
        api_patterns = [
            r'["\']([^"\']*api[^"\']*)["\']',
            r'["\']([^"\']*\/[^"\']*\.php[^"\']*)["\']',
            r'["\']([^"\']*\/[^"\']*\.json[^"\']*)["\']',
            r'["\']([^"\']*supabase[^"\']*)["\']'
        ]
        
        for pattern in api_patterns:
            matches = re.findall(pattern, js_content, re.IGNORECASE)
            analysis['api_endpoints'].extend(matches)
        
        # æŸ¥æ‰¾æ•…äº‹ç›¸å…³çš„ä»£ç 
        story_patterns = [
            r'story[^a-zA-Z].*',
            r'loadStory.*',
            r'getStory.*',
            r'showStory.*',
            r'storyId.*',
            r'story_id.*'
        ]
        
        for pattern in story_patterns:
            matches = re.findall(pattern, js_content, re.IGNORECASE)
            analysis['story_related'].extend(matches[:10])  # é™åˆ¶æ•°é‡
        
        # æŸ¥æ‰¾è·¯ç”±é€»è¾‘
        routing_patterns = [
            r'location\.hash.*',
            r'window\.location.*',
            r'hashchange.*',
            r'router.*',
            r'route.*'
        ]
        
        for pattern in routing_patterns:
            matches = re.findall(pattern, js_content, re.IGNORECASE)
            analysis['routing_logic'].extend(matches[:10])
        
        # æŸ¥æ‰¾æ•°æ®åº“æ“ä½œ
        db_patterns = [
            r'supabase.*',
            r'\.from\s*\(',
            r'\.select\s*\(',
            r'\.insert\s*\(',
            r'\.update\s*\(',
            r'\.eq\s*\('
        ]
        
        for pattern in db_patterns:
            matches = re.findall(pattern, js_content, re.IGNORECASE)
            analysis['database_operations'].extend(matches[:10])
        
        # å»é‡
        for key in analysis:
            if isinstance(analysis[key], list):
                analysis[key] = list(set(analysis[key]))
        
        return analysis
    
    def monitor_network_requests(self):
        """ç›‘æ§ç½‘ç»œè¯·æ±‚"""
        driver = None
        try:
            driver = self.create_driver()
            if not driver:
                return None
            
            self.logger.info("ğŸ” å¼€å§‹ç›‘æ§ç½‘ç»œè¯·æ±‚...")
            
            # è®¿é—®ä¸»é¡µ
            driver.get(self.base_url)
            time.sleep(3)
            
            # è·å–åˆå§‹ç½‘ç»œæ—¥å¿—
            initial_logs = driver.get_log('performance')
            
            # æµ‹è¯•ä¸åŒçš„æ•…äº‹ID
            story_ids = [1, 2, 3, 5, 10, 100]
            network_analysis = {}
            
            for story_id in story_ids:
                self.logger.info(f"ğŸ” æµ‹è¯•æ•…äº‹ID: {story_id}")
                
                # æ¸…é™¤ä¹‹å‰çš„æ—¥å¿—
                driver.get_log('performance')
                
                # ä¿®æ”¹hash
                driver.execute_script(f"window.location.hash = '#story/{story_id}';")
                time.sleep(5)
                
                # è·å–ç½‘ç»œæ—¥å¿—
                logs = driver.get_log('performance')
                
                # åˆ†æç½‘ç»œè¯·æ±‚
                requests_made = []
                for log in logs:
                    message = json.loads(log['message'])
                    if message['message']['method'] == 'Network.requestWillBeSent':
                        request_url = message['message']['params']['request']['url']
                        if 'storynook.cn' in request_url or 'supabase' in request_url:
                            requests_made.append({
                                'url': request_url,
                                'method': message['message']['params']['request']['method'],
                                'timestamp': log['timestamp']
                            })
                
                # æ£€æŸ¥é¡µé¢å†…å®¹å˜åŒ–
                page_text = driver.execute_script("return document.body.innerText;")
                
                network_analysis[f"story_{story_id}"] = {
                    'requests': requests_made,
                    'page_text_length': len(page_text),
                    'current_url': driver.current_url,
                    'page_title': driver.title
                }
                
                self.logger.info(f"  å‘ç° {len(requests_made)} ä¸ªç›¸å…³ç½‘ç»œè¯·æ±‚")
                for req in requests_made:
                    self.logger.info(f"    {req['method']} {req['url']}")
            
            return network_analysis
            
        except Exception as e:
            self.logger.error(f"âŒ ç›‘æ§ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
            return None
        finally:
            if driver:
                driver.quit()
    
    def test_direct_api_calls(self):
        """ç›´æ¥æµ‹è¯•APIè°ƒç”¨"""
        self.logger.info("ğŸ”¬ å¼€å§‹ç›´æ¥APIæµ‹è¯•...")
        
        # å¯èƒ½çš„APIç«¯ç‚¹
        api_endpoints = [
            f"{self.base_url}/api/story/1",
            f"{self.base_url}/api/story/2",
            f"{self.base_url}/api/stories",
            f"{self.base_url}/story/1.json",
            f"{self.base_url}/story/2.json",
            f"{self.base_url}/data/story/1",
            f"{self.base_url}/data/story/2"
        ]
        
        api_results = {}
        
        for endpoint in api_endpoints:
            try:
                self.logger.info(f"ğŸ” æµ‹è¯•APIç«¯ç‚¹: {endpoint}")
                
                response = requests.get(endpoint, timeout=10)
                
                api_results[endpoint] = {
                    'status_code': response.status_code,
                    'content_type': response.headers.get('content-type', ''),
                    'content_length': len(response.content),
                    'success': response.status_code == 200
                }
                
                if response.status_code == 200:
                    self.logger.info(f"âœ… APIç«¯ç‚¹æœ‰æ•ˆ: {endpoint}")
                    # ä¿å­˜å“åº”å†…å®¹
                    filename = endpoint.replace('/', '_').replace(':', '').replace('.', '_') + '.txt'
                    with open(f"api_response_{filename}", 'w', encoding='utf-8') as f:
                        f.write(response.text)
                else:
                    self.logger.info(f"âŒ APIç«¯ç‚¹æ— æ•ˆ: {endpoint} (çŠ¶æ€ç : {response.status_code})")
                
            except Exception as e:
                self.logger.error(f"âŒ æµ‹è¯•APIç«¯ç‚¹ {endpoint} å¤±è´¥: {e}")
                api_results[endpoint] = {'error': str(e), 'success': False}
        
        return api_results
    
    def analyze_supabase_integration(self):
        """åˆ†æSupabaseé›†æˆ"""
        driver = None
        try:
            driver = self.create_driver()
            if not driver:
                return None
            
            self.logger.info("ğŸ” åˆ†æSupabaseé›†æˆ...")
            
            # è®¿é—®ä¸»é¡µ
            driver.get(self.base_url)
            time.sleep(5)
            
            # æ£€æŸ¥Supabaseé…ç½®
            supabase_info = driver.execute_script("""
                var info = {
                    supabase_exists: typeof window.supabase !== 'undefined',
                    supabase_client_exists: typeof window.supabaseClient !== 'undefined',
                    global_vars: []
                };
                
                // æ£€æŸ¥å…¨å±€å˜é‡
                for (var key in window) {
                    if (key.toLowerCase().includes('supabase') || 
                        key.toLowerCase().includes('client') ||
                        key.toLowerCase().includes('database') ||
                        key.toLowerCase().includes('db')) {
                        info.global_vars.push({
                            name: key,
                            type: typeof window[key],
                            value_preview: typeof window[key] === 'object' ? 
                                Object.keys(window[key] || {}).slice(0, 5) : 
                                String(window[key]).substring(0, 100)
                        });
                    }
                }
                
                return info;
            """)
            
            self.logger.info(f"Supabaseå­˜åœ¨: {supabase_info.get('supabase_exists', False)}")
            self.logger.info(f"Supabaseå®¢æˆ·ç«¯å­˜åœ¨: {supabase_info.get('supabase_client_exists', False)}")
            
            # å°è¯•è°ƒç”¨æ•…äº‹åŠ è½½å‡½æ•°
            story_load_test = driver.execute_script("""
                var result = {
                    loadStoryDetail_exists: typeof loadStoryDetail === 'function',
                    test_results: []
                };
                
                if (typeof loadStoryDetail === 'function') {
                    try {
                        // å°è¯•è°ƒç”¨loadStoryDetailå‡½æ•°
                        var testResult = loadStoryDetail(1);
                        result.test_results.push({
                            story_id: 1,
                            result: testResult,
                            success: true
                        });
                    } catch (e) {
                        result.test_results.push({
                            story_id: 1,
                            error: e.toString(),
                            success: false
                        });
                    }
                }
                
                return result;
            """)
            
            return {
                'supabase_info': supabase_info,
                'story_load_test': story_load_test
            }
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†æSupabaseé›†æˆå¤±è´¥: {e}")
            return None
        finally:
            if driver:
                driver.quit()
    
    def generate_complete_analysis(self):
        """ç”Ÿæˆå®Œæ•´çš„æ·±åº¦åˆ†ææŠ¥å‘Š"""
        self.logger.info("ğŸš€ å¼€å§‹æ·±åº¦JavaScriptåˆ†æ...")
        
        # 1. ä¸‹è½½å¹¶åˆ†æJSæ–‡ä»¶
        js_analysis = self.download_and_analyze_js()
        
        # 2. ç›‘æ§ç½‘ç»œè¯·æ±‚
        network_analysis = self.monitor_network_requests()
        
        # 3. æµ‹è¯•ç›´æ¥APIè°ƒç”¨
        api_analysis = self.test_direct_api_calls()
        
        # 4. åˆ†æSupabaseé›†æˆ
        supabase_analysis = self.analyze_supabase_integration()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'analysis_time': datetime.now().isoformat(),
            'website_url': self.base_url,
            'javascript_analysis': js_analysis,
            'network_analysis': network_analysis,
            'api_analysis': api_analysis,
            'supabase_analysis': supabase_analysis,
            'recommendations': self.generate_crawling_strategy(js_analysis, network_analysis, api_analysis, supabase_analysis)
        }
        
        # ä¿å­˜æŠ¥å‘Š
        with open('deep_js_analysis_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        self.logger.info("ğŸ“‹ æ·±åº¦åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: deep_js_analysis_report.json")
        
        # æ‰“å°å…³é”®å‘ç°
        self.print_analysis_summary(report)
        
        return report
    
    def generate_crawling_strategy(self, js_analysis, network_analysis, api_analysis, supabase_analysis):
        """ç”Ÿæˆçˆ¬å–ç­–ç•¥"""
        strategies = []
        
        # åŸºäºJavaScriptåˆ†æçš„ç­–ç•¥
        if js_analysis:
            for filename, analysis in js_analysis.items():
                if 'error' not in analysis:
                    if analysis.get('story_related'):
                        strategies.append({
                            'type': 'javascript_function_call',
                            'description': f'åœ¨{filename}ä¸­å‘ç°æ•…äº‹ç›¸å…³å‡½æ•°',
                            'functions': analysis['story_related'][:5],
                            'implementation': 'ä½¿ç”¨Seleniumæ‰§è¡ŒJavaScriptå‡½æ•°æ¥åŠ è½½æ•…äº‹'
                        })
                    
                    if analysis.get('database_operations'):
                        strategies.append({
                            'type': 'supabase_database',
                            'description': f'åœ¨{filename}ä¸­å‘ç°æ•°æ®åº“æ“ä½œ',
                            'operations': analysis['database_operations'][:5],
                            'implementation': 'æ¨¡æ‹ŸSupabaseæ•°æ®åº“æŸ¥è¯¢'
                        })
        
        # åŸºäºç½‘ç»œåˆ†æçš„ç­–ç•¥
        if network_analysis:
            unique_requests = set()
            for story_key, data in network_analysis.items():
                for req in data.get('requests', []):
                    unique_requests.add(req['url'])
            
            if unique_requests:
                strategies.append({
                    'type': 'network_request_monitoring',
                    'description': 'å‘ç°åŠ¨æ€ç½‘ç»œè¯·æ±‚',
                    'unique_requests': list(unique_requests),
                    'implementation': 'ç›‘æ§å¹¶å¤åˆ¶ç½‘ç»œè¯·æ±‚æ¨¡å¼'
                })
        
        # åŸºäºAPIåˆ†æçš„ç­–ç•¥
        if api_analysis:
            working_apis = [endpoint for endpoint, data in api_analysis.items() 
                          if data.get('success', False)]
            if working_apis:
                strategies.append({
                    'type': 'direct_api_access',
                    'description': 'å‘ç°å¯ç”¨çš„APIç«¯ç‚¹',
                    'endpoints': working_apis,
                    'implementation': 'ç›´æ¥è°ƒç”¨APIç«¯ç‚¹è·å–æ•°æ®'
                })
        
        # åŸºäºSupabaseåˆ†æçš„ç­–ç•¥
        if supabase_analysis:
            if supabase_analysis.get('supabase_info', {}).get('supabase_exists'):
                strategies.append({
                    'type': 'supabase_client_simulation',
                    'description': 'æ£€æµ‹åˆ°Supabaseå®¢æˆ·ç«¯',
                    'implementation': 'æ¨¡æ‹ŸSupabaseå®¢æˆ·ç«¯è°ƒç”¨'
                })
        
        return strategies
    
    def print_analysis_summary(self, report):
        """æ‰“å°åˆ†ææ€»ç»“"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ”¬ æ·±åº¦JavaScriptåˆ†ææ€»ç»“")
        self.logger.info("="*60)
        
        # JavaScriptæ–‡ä»¶åˆ†æ
        if report.get('javascript_analysis'):
            self.logger.info("ğŸ“œ JavaScriptæ–‡ä»¶åˆ†æ:")
            for filename, analysis in report['javascript_analysis'].items():
                if 'error' not in analysis:
                    self.logger.info(f"  {filename}:")
                    self.logger.info(f"    å‡½æ•°æ•°é‡: {len(analysis.get('functions', []))}")
                    self.logger.info(f"    AJAXè°ƒç”¨: {len(analysis.get('ajax_calls', []))}")
                    self.logger.info(f"    æ•…äº‹ç›¸å…³ä»£ç : {len(analysis.get('story_related', []))}")
                    self.logger.info(f"    æ•°æ®åº“æ“ä½œ: {len(analysis.get('database_operations', []))}")
        
        # ç½‘ç»œè¯·æ±‚åˆ†æ
        if report.get('network_analysis'):
            total_requests = sum(len(data.get('requests', [])) 
                               for data in report['network_analysis'].values())
            self.logger.info(f"ğŸŒ ç½‘ç»œè¯·æ±‚ç›‘æ§: æ€»å…±å‘ç° {total_requests} ä¸ªè¯·æ±‚")
        
        # APIæµ‹è¯•ç»“æœ
        if report.get('api_analysis'):
            working_apis = sum(1 for data in report['api_analysis'].values() 
                             if data.get('success', False))
            total_apis = len(report['api_analysis'])
            self.logger.info(f"ğŸ”Œ APIæµ‹è¯•: {working_apis}/{total_apis} ä¸ªç«¯ç‚¹å¯ç”¨")
        
        # Supabaseåˆ†æ
        if report.get('supabase_analysis'):
            supabase_exists = report['supabase_analysis'].get('supabase_info', {}).get('supabase_exists', False)
            self.logger.info(f"ğŸ—„ï¸ Supabaseé›†æˆ: {'æ£€æµ‹åˆ°' if supabase_exists else 'æœªæ£€æµ‹åˆ°'}")
        
        # çˆ¬å–ç­–ç•¥
        if report.get('recommendations'):
            self.logger.info("ğŸ’¡ æ¨èçš„çˆ¬å–ç­–ç•¥:")
            for i, strategy in enumerate(report['recommendations'], 1):
                self.logger.info(f"  {i}. {strategy['type']}: {strategy['description']}")
        
        self.logger.info("="*60)

def main():
    analyzer = DeepJSAnalyzer()
    
    try:
        # ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š
        report = analyzer.generate_complete_analysis()
        
        print("\nğŸ‰ æ·±åº¦JavaScriptåˆ†æå®Œæˆï¼")
        print("ğŸ“‹ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: deep_js_analysis_report.json")
        print("ğŸ“œ æ—¥å¿—æ–‡ä»¶: deep_js_analyzer.log")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­åˆ†æ")
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()