#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆå¤§è§„æ¨¡çˆ¬è™« - ä¸“é—¨çˆ¬å– storynook.cn çš„æ‰€æœ‰æ•…äº‹
ä½¿ç”¨ç°æœ‰ChromeDriverï¼Œæ”¯æŒæ·±åº¦æ»šåŠ¨å’Œå¤šç­–ç•¥æŠ“å–
"""

import time
import json
import re
import sqlite3
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import logging
import requests
from urllib.parse import urljoin

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enhanced_mass_crawler.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class EnhancedMassCrawler:
    def __init__(self):
        self.base_url = "https://storynook.cn/"
        self.driver = None
        self.all_stories = {}  # ä½¿ç”¨å­—å…¸å»é‡
        self.story_contents = {}
        self.crawl_stats = {
            "start_time": datetime.now().isoformat(),
            "stories_found": 0,
            "stories_with_content": 0,
            "scroll_attempts": 0,
            "errors": 0
        }
        self.max_scroll_attempts = 50  # å¢åŠ æ»šåŠ¨æ¬¡æ•°
        self.max_stories_target = 500  # ç›®æ ‡æ•…äº‹æ•°é‡
        
    def setup_driver(self):
        """è®¾ç½®Chrome WebDriver - ä½¿ç”¨ç°æœ‰é©±åŠ¨"""
        try:
            chrome_options = Options()
            # ä¸ä½¿ç”¨headlessæ¨¡å¼ï¼Œä¾¿äºè°ƒè¯•
            # chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            # å°è¯•ä½¿ç”¨ç°æœ‰çš„ChromeDriver
            try:
                self.driver = webdriver.Chrome(options=chrome_options)
            except Exception as e:
                logger.warning(f"ä½¿ç”¨é»˜è®¤ChromeDriverå¤±è´¥: {e}")
                # å°è¯•ä½¿ç”¨æœ¬åœ°ChromeDriver
                chrome_options.add_argument('--remote-debugging-port=9222')
                self.driver = webdriver.Chrome(options=chrome_options)
            
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.set_page_load_timeout(30)
            logger.info("WebDriver è®¾ç½®æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"WebDriver è®¾ç½®å¤±è´¥: {e}")
            return False
    
    def extract_stories_from_current_page(self):
        """ä»å½“å‰é¡µé¢æå–æ‰€æœ‰æ•…äº‹"""
        try:
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            time.sleep(2)
            
            # æ–¹æ³•1: é€šè¿‡onclickå±æ€§æå–
            story_elements = self.driver.find_elements(By.CSS_SELECTOR, "[onclick*='showStory']")
            new_stories_count = 0
            
            for element in story_elements:
                try:
                    onclick = element.get_attribute('onclick')
                    if onclick and 'showStory' in onclick:
                        story_id_match = re.search(r'showStory\((\d+)\)', onclick)
                        if story_id_match:
                            story_id = int(story_id_match.group(1))
                            title = element.text.strip()
                            
                            if story_id not in self.all_stories and title:
                                self.all_stories[story_id] = {
                                    "id": story_id,
                                    "title": title,
                                    "category_name": "ç¡å‰æ•…äº‹",
                                    "extracted_at": datetime.now().isoformat(),
                                    "source": "selenium_onclick"
                                }
                                new_stories_count += 1
                except Exception as e:
                    continue
            
            # æ–¹æ³•2: é€šè¿‡é¡µé¢æºç æ­£åˆ™æå–
            try:
                page_source = self.driver.page_source
                onclick_pattern = r'onclick=["\']showStory\((\d+)\)["\'][^>]*>([^<]+)'
                matches = re.findall(onclick_pattern, page_source)
                
                for story_id, title in matches:
                    story_id = int(story_id)
                    title = title.strip()
                    if story_id not in self.all_stories and title:
                        self.all_stories[story_id] = {
                            "id": story_id,
                            "title": title,
                            "category_name": "ç¡å‰æ•…äº‹",
                            "extracted_at": datetime.now().isoformat(),
                            "source": "regex_page_source"
                        }
                        new_stories_count += 1
            except Exception as e:
                logger.warning(f"æ­£åˆ™æå–å¤±è´¥: {e}")
            
            logger.info(f"æœ¬æ¬¡æå–æ–°å¢ {new_stories_count} ä¸ªæ•…äº‹ï¼Œæ€»è®¡ {len(self.all_stories)} ä¸ª")
            return new_stories_count
            
        except Exception as e:
            logger.error(f"æå–æ•…äº‹å¤±è´¥: {e}")
            return 0
    
    def aggressive_scroll_and_load(self):
        """æ¿€è¿›çš„æ»šåŠ¨å’ŒåŠ è½½ç­–ç•¥"""
        try:
            logger.info("å¼€å§‹æ¿€è¿›æ»šåŠ¨ç­–ç•¥...")
            
            scroll_count = 0
            consecutive_no_new = 0
            last_story_count = 0
            
            while (scroll_count < self.max_scroll_attempts and 
                   len(self.all_stories) < self.max_stories_target and 
                   consecutive_no_new < 5):
                
                # è®°å½•æ»šåŠ¨å‰çš„æ•…äº‹æ•°é‡
                before_count = len(self.all_stories)
                
                # å¤šç§æ»šåŠ¨ç­–ç•¥
                if scroll_count % 3 == 0:
                    # æ»šåŠ¨åˆ°åº•éƒ¨
                    self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                elif scroll_count % 3 == 1:
                    # åˆ†æ®µæ»šåŠ¨
                    self.driver.execute_script("window.scrollBy(0, 1000);")
                else:
                    # æ»šåŠ¨åˆ°ç‰¹å®šä½ç½®
                    self.driver.execute_script(f"window.scrollTo(0, {scroll_count * 500});")
                
                time.sleep(1.5)
                
                # å°è¯•ç‚¹å‡»å„ç§å¯èƒ½çš„åŠ è½½æŒ‰é’®
                load_buttons = [
                    "button:contains('æ›´å¤š')",
                    "button:contains('åŠ è½½')", 
                    ".load-more",
                    ".more-btn",
                    "[onclick*='loadMore']",
                    "[onclick*='more']",
                    "a:contains('æ›´å¤š')",
                    ".btn-more"
                ]
                
                for selector in load_buttons:
                    try:
                        buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        for button in buttons:
                            if button.is_displayed() and button.is_enabled():
                                self.driver.execute_script("arguments[0].click();", button)
                                time.sleep(2)
                                logger.info(f"ç‚¹å‡»äº†åŠ è½½æŒ‰é’®: {selector}")
                                break
                    except:
                        continue
                
                # å°è¯•è§¦å‘JavaScriptäº‹ä»¶
                try:
                    self.driver.execute_script("""
                        // å°è¯•è§¦å‘æ»šåŠ¨äº‹ä»¶
                        window.dispatchEvent(new Event('scroll'));
                        window.dispatchEvent(new Event('resize'));
                        
                        // å°è¯•è°ƒç”¨å¯èƒ½çš„åŠ è½½å‡½æ•°
                        if(typeof loadMore === 'function') loadMore();
                        if(typeof loadMoreStories === 'function') loadMoreStories();
                        if(typeof showMore === 'function') showMore();
                    """)
                except:
                    pass
                
                # æå–å½“å‰é¡µé¢çš„æ•…äº‹
                new_stories = self.extract_stories_from_current_page()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ•…äº‹
                after_count = len(self.all_stories)
                if after_count == before_count:
                    consecutive_no_new += 1
                else:
                    consecutive_no_new = 0
                
                scroll_count += 1
                self.crawl_stats["scroll_attempts"] = scroll_count
                
                logger.info(f"æ»šåŠ¨ {scroll_count}/{self.max_scroll_attempts}, "
                          f"æ•…äº‹æ€»æ•°: {after_count}, "
                          f"è¿ç»­æ— æ–°æ•…äº‹: {consecutive_no_new}")
                
                # ç­‰å¾…é¡µé¢ç¨³å®š
                time.sleep(1)
            
            logger.info(f"æ»šåŠ¨å®Œæˆï¼Œå…±å‘ç° {len(self.all_stories)} ä¸ªæ•…äº‹")
            return True
            
        except Exception as e:
            logger.error(f"æ»šåŠ¨ç­–ç•¥å¤±è´¥: {e}")
            return False
    
    def get_story_content_batch(self, story_ids, max_attempts=3):
        """æ‰¹é‡è·å–æ•…äº‹å†…å®¹"""
        try:
            logger.info(f"å¼€å§‹æ‰¹é‡è·å– {len(story_ids)} ä¸ªæ•…äº‹çš„å†…å®¹...")
            success_count = 0
            
            for i, story_id in enumerate(story_ids):
                attempts = 0
                content = None
                
                while attempts < max_attempts and not content:
                    try:
                        # å°è¯•é€šè¿‡JavaScriptè·å–å†…å®¹
                        content = self.driver.execute_script(f"""
                            return new Promise((resolve) => {{
                                try {{
                                    if(typeof showStory === 'function') {{
                                        showStory({story_id});
                                        
                                        setTimeout(() => {{
                                            var selectors = [
                                                '#storyModal .modal-body',
                                                '.story-content',
                                                '.modal-content',
                                                '#story-content',
                                                '.story-text'
                                            ];
                                            
                                            for(var sel of selectors) {{
                                                var modal = document.querySelector(sel);
                                                if(modal && modal.textContent.trim().length > 50) {{
                                                    resolve(modal.textContent.trim());
                                                    return;
                                                }}
                                            }}
                                            resolve(null);
                                        }}, 2000);
                                    }} else {{
                                        resolve(null);
                                    }}
                                }} catch(e) {{
                                    resolve(null);
                                }}
                            }});
                        """)
                        
                        if content and len(content) > 50:
                            self.story_contents[story_id] = {
                                "id": story_id,
                                "content": content,
                                "length": len(content),
                                "extracted_at": datetime.now().isoformat()
                            }
                            
                            # æ›´æ–°æ•…äº‹ä¿¡æ¯
                            if story_id in self.all_stories:
                                self.all_stories[story_id]["content_length"] = len(content)
                                self.all_stories[story_id]["has_content"] = True
                            
                            success_count += 1
                            break
                        
                    except Exception as e:
                        logger.warning(f"è·å–æ•…äº‹ {story_id} å†…å®¹å¤±è´¥ (å°è¯• {attempts + 1}): {e}")
                    
                    attempts += 1
                    time.sleep(1)
                
                if (i + 1) % 10 == 0:
                    logger.info(f"å·²å¤„ç† {i + 1}/{len(story_ids)} ä¸ªæ•…äº‹ï¼ŒæˆåŠŸ: {success_count}")
                
                time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
            
            logger.info(f"æ‰¹é‡è·å–å®Œæˆï¼ŒæˆåŠŸè·å– {success_count} ä¸ªæ•…äº‹å†…å®¹")
            self.crawl_stats["stories_with_content"] = success_count
            return success_count
            
        except Exception as e:
            logger.error(f"æ‰¹é‡è·å–æ•…äº‹å†…å®¹å¤±è´¥: {e}")
            return 0
    
    def save_all_data(self):
        """ä¿å­˜æ‰€æœ‰æ•°æ®"""
        try:
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.crawl_stats["end_time"] = datetime.now().isoformat()
            self.crawl_stats["stories_found"] = len(self.all_stories)
            
            # ä¿å­˜æ•…äº‹åˆ—è¡¨
            stories_list = list(self.all_stories.values())
            with open('mass_crawled_stories.json', 'w', encoding='utf-8') as f:
                json.dump(stories_list, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜æ•…äº‹å†…å®¹
            if self.story_contents:
                contents_list = list(self.story_contents.values())
                with open('mass_story_contents.json', 'w', encoding='utf-8') as f:
                    json.dump(contents_list, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜åˆ°SQLiteæ•°æ®åº“
            self.save_to_database()
            
            # ä¿å­˜çˆ¬å–æŠ¥å‘Š
            with open('mass_crawl_report.json', 'w', encoding='utf-8') as f:
                json.dump(self.crawl_stats, f, ensure_ascii=False, indent=2)
            
            logger.info("æ‰€æœ‰æ•°æ®ä¿å­˜æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            return False
    
    def save_to_database(self):
        """ä¿å­˜åˆ°SQLiteæ•°æ®åº“"""
        try:
            conn = sqlite3.connect('mass_crawled_stories.db')
            cursor = conn.cursor()
            
            # åˆ›å»ºæ•…äº‹è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS stories (
                    id INTEGER PRIMARY KEY,
                    title TEXT NOT NULL,
                    category_name TEXT,
                    content_length INTEGER DEFAULT 0,
                    has_content BOOLEAN DEFAULT FALSE,
                    extracted_at TEXT,
                    source TEXT
                )
            ''')
            
            # åˆ›å»ºæ•…äº‹å†…å®¹è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS story_contents (
                    id INTEGER PRIMARY KEY,
                    content TEXT NOT NULL,
                    length INTEGER,
                    extracted_at TEXT
                )
            ''')
            
            # æ’å…¥æ•…äº‹æ•°æ®
            for story in self.all_stories.values():
                cursor.execute('''
                    INSERT OR REPLACE INTO stories 
                    (id, title, category_name, content_length, has_content, extracted_at, source)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    story["id"],
                    story["title"],
                    story.get("category_name", "ç¡å‰æ•…äº‹"),
                    story.get("content_length", 0),
                    story.get("has_content", False),
                    story["extracted_at"],
                    story.get("source", "unknown")
                ))
            
            # æ’å…¥æ•…äº‹å†…å®¹
            for content in self.story_contents.values():
                cursor.execute('''
                    INSERT OR REPLACE INTO story_contents 
                    (id, content, length, extracted_at)
                    VALUES (?, ?, ?, ?)
                ''', (
                    content["id"],
                    content["content"],
                    content["length"],
                    content["extracted_at"]
                ))
            
            conn.commit()
            conn.close()
            
            logger.info("æ•°æ®åº“ä¿å­˜æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def run_mass_crawl(self):
        """è¿è¡Œå¤§è§„æ¨¡çˆ¬å–"""
        try:
            logger.info("å¼€å§‹å¤§è§„æ¨¡æ•…äº‹çˆ¬å–...")
            
            if not self.setup_driver():
                return False
            
            # è®¿é—®ä¸»é¡µ
            logger.info("è®¿é—®ä¸»é¡µ...")
            self.driver.get(self.base_url)
            time.sleep(3)
            
            # æ‰§è¡Œæ¿€è¿›æ»šåŠ¨ç­–ç•¥
            self.aggressive_scroll_and_load()
            
            # å¦‚æœå‘ç°äº†æ•…äº‹ï¼Œå°è¯•è·å–å†…å®¹
            if self.all_stories:
                story_ids = list(self.all_stories.keys())[:100]  # è·å–å‰100ä¸ªæ•…äº‹çš„å†…å®¹
                self.get_story_content_batch(story_ids)
            
            # ä¿å­˜æ‰€æœ‰æ•°æ®
            self.save_all_data()
            
            logger.info("å¤§è§„æ¨¡çˆ¬å–å®Œæˆï¼")
            logger.info(f"æ€»å…±å‘ç° {len(self.all_stories)} ä¸ªæ•…äº‹")
            logger.info(f"è·å–åˆ° {len(self.story_contents)} ä¸ªæ•…äº‹çš„å®Œæ•´å†…å®¹")
            
            return True
            
        except Exception as e:
            logger.error(f"å¤§è§„æ¨¡çˆ¬å–å¤±è´¥: {e}")
            return False
        finally:
            if self.driver:
                self.driver.quit()

def main():
    crawler = EnhancedMassCrawler()
    success = crawler.run_mass_crawl()
    
    if success:
        print("âœ… å¤§è§„æ¨¡çˆ¬å–å®Œæˆï¼")
        print("ğŸ“Š çˆ¬å–ç»“æœ:")
        print(f"   - å‘ç°æ•…äº‹: {len(crawler.all_stories)} ä¸ª")
        print(f"   - è·å–å†…å®¹: {len(crawler.story_contents)} ä¸ª")
        print("ğŸ“ ç”Ÿæˆæ–‡ä»¶:")
        print("   - mass_crawled_stories.json (æ‰€æœ‰æ•…äº‹åˆ—è¡¨)")
        print("   - mass_story_contents.json (æ•…äº‹å†…å®¹)")
        print("   - mass_crawled_stories.db (SQLiteæ•°æ®åº“)")
        print("   - mass_crawl_report.json (çˆ¬å–æŠ¥å‘Š)")
    else:
        print("âŒ å¤§è§„æ¨¡çˆ¬å–å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶")

if __name__ == "__main__":
    main()