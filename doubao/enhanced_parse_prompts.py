#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆè±†åŒ…æç¤ºè¯è§£æè„šæœ¬
ç¡®ä¿å®Œæ•´æå–æ‰€æœ‰Wordå’Œæ–‡æœ¬æ–‡ä»¶ä¸­çš„æç¤ºè¯å†…å®¹
"""

import os
import json
import re
from pathlib import Path
from docx import Document
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('parse_log.txt', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class EnhancedPromptParser:
    def __init__(self, source_dir, output_file):
        self.source_dir = Path(source_dir)
        self.output_file = output_file
        self.prompts = []
        self.stats = {
            'total_files': 0,
            'docx_files': 0,
            'txt_files': 0,
            'parsed_successfully': 0,
            'failed_files': [],
            'categories': {}
        }
        
        # åˆ†ç±»æ˜ å°„è¡¨
        self.category_mapping = {
            '01è‡ªåª’ä½“ç±»å‹': 'è‡ªåª’ä½“',
            '02å…¬æ–‡ç±»': 'å…¬æ–‡å†™ä½œ',
            '03.è‹±è¯­ç±»å‹': 'è‹±è¯­å­¦ä¹ ',
            '04.è®ºæ–‡ç±»': 'è®ºæ–‡å†™ä½œ',
            '5.ä»¿å†™ç±»': 'ä»¿å†™åˆ›ä½œ',
            '6.å½±è§†å°è¯´ç±»': 'å½±è§†å°è¯´',
            '7.è¥é”€ç­–åˆ’ç±»': 'è¥é”€ç­–åˆ’',
            '8.èŒåœºç±»': 'èŒåœºåŠå…¬',
            'æ›´æ–°': 'å›¾åƒç”Ÿæˆ'  # æ›´æ–°ç›®å½•ä¸»è¦æ˜¯å›¾åƒç”Ÿæˆç›¸å…³
        }

    def scan_all_files(self):
        """æ‰«ææ‰€æœ‰æ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶åˆ—è¡¨"""
        files = []
        for ext in ['*.docx', '*.txt']:
            files.extend(self.source_dir.rglob(ext))
        
        self.stats['total_files'] = len(files)
        self.stats['docx_files'] = len([f for f in files if f.suffix == '.docx'])
        self.stats['txt_files'] = len([f for f in files if f.suffix == '.txt'])
        
        logging.info(f"æ‰«æå®Œæˆ: æ€»æ–‡ä»¶æ•° {self.stats['total_files']}")
        logging.info(f"Wordæ–‡æ¡£: {self.stats['docx_files']}, æ–‡æœ¬æ–‡ä»¶: {self.stats['txt_files']}")
        
        return files

    def extract_from_docx(self, file_path):
        """ä»Wordæ–‡æ¡£æå–å†…å®¹"""
        try:
            doc = Document(file_path)
            content_parts = []
            
            # æå–æ‰€æœ‰æ®µè½
            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                if text:
                    content_parts.append(text)
            
            # æå–è¡¨æ ¼å†…å®¹
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        text = cell.text.strip()
                        if text:
                            content_parts.append(text)
            
            full_content = '\n'.join(content_parts)
            
            if not full_content.strip():
                logging.warning(f"Wordæ–‡æ¡£å†…å®¹ä¸ºç©º: {file_path}")
                return None
                
            return full_content
            
        except Exception as e:
            logging.error(f"è§£æWordæ–‡æ¡£å¤±è´¥ {file_path}: {str(e)}")
            return None

    def extract_from_txt(self, file_path):
        """ä»æ–‡æœ¬æ–‡ä»¶æå–å†…å®¹"""
        try:
            # å°è¯•å¤šç§ç¼–ç 
            encodings = ['utf-8', 'gbk', 'gb2312', 'utf-16']
            
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read().strip()
                        if content:
                            return content
                except UnicodeDecodeError:
                    continue
            
            logging.error(f"æ— æ³•è§£ç æ–‡æœ¬æ–‡ä»¶: {file_path}")
            return None
            
        except Exception as e:
            logging.error(f"è¯»å–æ–‡æœ¬æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
            return None

    def determine_category(self, file_path):
        """æ ¹æ®æ–‡ä»¶è·¯å¾„ç¡®å®šåˆ†ç±»"""
        path_parts = file_path.parts
        
        # æŸ¥æ‰¾ä¸»åˆ†ç±»ç›®å½•
        for part in path_parts:
            for key, value in self.category_mapping.items():
                if key in part:
                    return value
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„åˆ†ç±»ï¼Œæ ¹æ®æ–‡ä»¶åæ¨æ–­
        filename = file_path.name.lower()
        if any(word in filename for word in ['ç¾å¥³', 'å›¾åƒ', 'ç”Ÿæˆ', 'cos', 'ç»˜æœ¬']):
            return 'å›¾åƒç”Ÿæˆ'
        elif any(word in filename for word in ['è‡ªåª’ä½“', 'æ–‡æ¡ˆ', 'å°çº¢ä¹¦', 'å…¬ä¼—å·']):
            return 'è‡ªåª’ä½“'
        elif any(word in filename for word in ['å…¬æ–‡', 'ppt', 'ä¼šè®®']):
            return 'å…¬æ–‡å†™ä½œ'
        elif any(word in filename for word in ['è‹±è¯­', 'å•è¯']):
            return 'è‹±è¯­å­¦ä¹ '
        elif any(word in filename for word in ['è®ºæ–‡', 'å†™ä½œ']):
            return 'è®ºæ–‡å†™ä½œ'
        elif any(word in filename for word in ['ä»¿å†™', 'å°è¯´', 'æ•…äº‹']):
            return 'ä»¿å†™åˆ›ä½œ'
        elif any(word in filename for word in ['å½±è§†', 'å‰§æœ¬', 'ç”µå½±']):
            return 'å½±è§†å°è¯´'
        elif any(word in filename for word in ['è¥é”€', 'ç­–åˆ’']):
            return 'è¥é”€ç­–åˆ’'
        elif any(word in filename for word in ['èŒåœº', 'é¢è¯•', 'è§„åˆ’']):
            return 'èŒåœºåŠå…¬'
        
        return 'å…¶ä»–'

    def clean_title(self, filename):
        """æ¸…ç†æ–‡ä»¶åä½œä¸ºæ ‡é¢˜"""
        # ç§»é™¤æ–‡ä»¶æ‰©å±•å
        title = filename.replace('.docx', '').replace('.txt', '')
        
        # ç§»é™¤å¸¸è§çš„æ ‡è®°
        patterns = [
            r'ã€æŒ‡ä»¤\+?.*?ã€‘',
            r'ã€æŒ‡ä»¤ã€‘',
            r'ã€æ•™ç¨‹ã€‘',
            r'ã€è§†é¢‘æ•™ç¨‹ã€‘',
            r'\d+ã€?',
            r'^\d+\.',
        ]
        
        for pattern in patterns:
            title = re.sub(pattern, '', title)
        
        return title.strip()

    def extract_description_and_content(self, full_content, title):
        """ä»å®Œæ•´å†…å®¹ä¸­æå–æè¿°å’Œä¸»è¦å†…å®¹"""
        if not full_content:
            return "æš‚æ— æè¿°", "æš‚æ— å†…å®¹"
        
        lines = [line.strip() for line in full_content.split('\n') if line.strip()]
        
        if not lines:
            return "æš‚æ— æè¿°", "æš‚æ— å†…å®¹"
        
        # å¦‚æœå†…å®¹å¾ˆçŸ­ï¼Œç›´æ¥ä½œä¸ºæè¿°å’Œå†…å®¹
        if len(lines) <= 3:
            description = lines[0] if lines else "æš‚æ— æè¿°"
            content = full_content
            return description, content
        
        # å¯»æ‰¾å¯èƒ½çš„æè¿°éƒ¨åˆ†
        description = ""
        content_start_idx = 0
        
        # æŸ¥æ‰¾æè¿°æ€§æ–‡å­—
        for i, line in enumerate(lines[:5]):  # åªæ£€æŸ¥å‰5è¡Œ
            if len(line) < 200 and not line.startswith(('Role:', 'Background:', 'Profile:')):
                if any(word in line for word in ['æç¤ºè¯', 'æŒ‡ä»¤', 'åŠ©æ‰‹', 'ä¸“å®¶', 'ç”Ÿæˆ', 'åˆ›ä½œ']):
                    description = line
                    content_start_idx = i + 1
                    break
        
        # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„æè¿°ï¼Œä½¿ç”¨ç¬¬ä¸€è¡Œ
        if not description:
            description = lines[0]
            content_start_idx = 1
        
        # æå–ä¸»è¦å†…å®¹
        content_lines = lines[content_start_idx:] if content_start_idx < len(lines) else lines
        content = '\n'.join(content_lines) if content_lines else full_content
        
        return description, content

    def parse_single_file(self, file_path):
        """è§£æå•ä¸ªæ–‡ä»¶"""
        logging.info(f"æ­£åœ¨è§£æ: {file_path}")
        
        # æå–å†…å®¹
        if file_path.suffix == '.docx':
            full_content = self.extract_from_docx(file_path)
        else:
            full_content = self.extract_from_txt(file_path)
        
        if not full_content:
            self.stats['failed_files'].append(str(file_path))
            return None
        
        # ç”Ÿæˆæ ‡é¢˜
        title = self.clean_title(file_path.name)
        
        # ç¡®å®šåˆ†ç±»
        category = self.determine_category(file_path)
        
        # æå–æè¿°å’Œå†…å®¹
        description, content = self.extract_description_and_content(full_content, title)
        
        # åˆ›å»ºæç¤ºè¯å¯¹è±¡
        prompt = {
            "æç¤ºè¯åç§°": title,
            "æç¤ºè¯æè¿°": description,
            "æç¤ºè¯å†…å®¹": content,
            "æç¤ºè¯åˆ†ç±»": category
        }
        
        # æ›´æ–°ç»Ÿè®¡
        if category not in self.stats['categories']:
            self.stats['categories'][category] = 0
        self.stats['categories'][category] += 1
        
        self.stats['parsed_successfully'] += 1
        logging.info(f"è§£ææˆåŠŸ: {title} -> {category}")
        
        return prompt

    def parse_all_files(self):
        """è§£ææ‰€æœ‰æ–‡ä»¶"""
        files = self.scan_all_files()
        
        logging.info("å¼€å§‹è§£ææ‰€æœ‰æ–‡ä»¶...")
        
        for file_path in files:
            prompt = self.parse_single_file(file_path)
            if prompt:
                self.prompts.append(prompt)
        
        logging.info(f"è§£æå®Œæˆ! æˆåŠŸ: {self.stats['parsed_successfully']}, å¤±è´¥: {len(self.stats['failed_files'])}")

    def save_to_json(self):
        """ä¿å­˜åˆ°JSONæ–‡ä»¶"""
        data = {
            "prompts": self.prompts
        }
        
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logging.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {self.output_file}")

    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*50)
        print("ğŸ“Š è§£æç»Ÿè®¡æŠ¥å‘Š")
        print("="*50)
        print(f"æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        print(f"Wordæ–‡æ¡£: {self.stats['docx_files']}")
        print(f"æ–‡æœ¬æ–‡ä»¶: {self.stats['txt_files']}")
        print(f"è§£ææˆåŠŸ: {self.stats['parsed_successfully']}")
        print(f"è§£æå¤±è´¥: {len(self.stats['failed_files'])}")
        
        print(f"\nğŸ“‚ åˆ†ç±»ç»Ÿè®¡:")
        for category, count in sorted(self.stats['categories'].items()):
            print(f"  {category}: {count}ä¸ª")
        
        if self.stats['failed_files']:
            print(f"\nâŒ å¤±è´¥æ–‡ä»¶:")
            for file in self.stats['failed_files']:
                print(f"  {file}")

def main():
    source_dir = r"f:\ä¸ªäººæ–‡æ¡£\website\salary\2025è±†åŒ…æŒ‡ä»¤85+æç¤ºè¯åˆé›†"
    output_file = "prompts.json"
    
    parser = EnhancedPromptParser(source_dir, output_file)
    parser.parse_all_files()
    parser.save_to_json()
    parser.print_statistics()

if __name__ == "__main__":
    main()