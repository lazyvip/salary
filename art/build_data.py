import json
import os
import random
import requests
import re
from PIL import Image
from io import BytesIO
import time

# Configuration
JSON_URL = "https://opennana.com/awesome-prompt-gallery/data/prompts.json"
BASE_IMG_URL = "https://opennana.com/awesome-prompt-gallery/"
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), "assets", "images")
DATA_JS_PATH = os.path.join(os.path.dirname(__file__), "data.js")
SAMPLE_SIZE = 50

# ğŸ§  æ‡’äººæ™ºèƒ½ï¼šä¼˜å…ˆæŠ“å–åŒ…å«è¿™äº›è¯çš„â€œå¤§ç‰‡â€ï¼Œä¿è¯è§†è§‰å†²å‡»åŠ›
# è¿™äº›è¯é€šå¸¸ä»£è¡¨äº†é«˜è´¨é‡çš„ç”Ÿæˆå‚æ•°
HOT_KEYWORDS = [
    "cyberpunk", "lighting", "realistic", "8k", "masterpiece", 
    "portrait", "landscape", "anime", "neon", "texture", 
    "detailed", "cinematic", "rendering", "unreal engine"
]

def ensure_dir(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

def clean_filename(text):
    """
    SEO æ ¸å¿ƒï¼šæŠŠæç¤ºè¯å˜æˆæ–‡ä»¶å
    ä¾‹å¦‚: "A beautiful cyberpunk girl..." -> "a-beautiful-cyberpunk-girl"
    """
    if not text:
        return "ai-generated-image"
    
    # 1. å–å‰ 8 ä¸ªå•è¯ (Google é€šå¸¸åªçœ‹å‰å‡ ä¸ªè¯)
    words = text.split()[:8]
    short_text = " ".join(words)
    
    # 2. åªä¿ç•™å­—æ¯æ•°å­—ï¼Œç©ºæ ¼å˜æ¨ªæ 
    cleaned = re.sub(r'[^a-zA-Z0-9\s]', '', short_text)
    slug = re.sub(r'\s+', '-', cleaned).strip().lower()
    
    # 3. é˜²æ­¢æ–‡ä»¶åä¸ºç©ºæˆ–è¿‡é•¿
    if len(slug) < 3:
        return f"ai-art-{int(time.time())}"
    return slug[:100]  # é™åˆ¶é•¿åº¦

def fetch_data():
    print(f"Fetching data from {JSON_URL}...")
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...'
        }
        resp = requests.get(JSON_URL, headers=headers, timeout=30)
        if resp.status_code == 200:
            data = resp.json()
            return data.get("items", [])
        return []
    except Exception as e:
        print(f"Error: {e}")
        return []

def smart_select_items(items, limit):
    """
    æ™ºèƒ½ç­›é€‰é€»è¾‘ï¼šä¼˜å…ˆé€‰å«â€œçƒ­è¯â€çš„ï¼Œä¸å¤Ÿçš„å†éšæœºè¡¥
    """
    print("ğŸ¤– Running Smart Selection...")
    high_quality_items = []
    other_items = []
    
    for item in items:
        # è·å–æç¤ºè¯æ–‡æœ¬
        prompts = item.get("prompts", [])
        p_text = str(prompts[0]).lower() if prompts else ""
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«çƒ­è¯
        if any(kw in p_text for kw in HOT_KEYWORDS):
            high_quality_items.append(item)
        else:
            other_items.append(item)
            
    print(f"Found {len(high_quality_items)} high-quality items based on keywords.")
    
    # ä¼˜å…ˆå–é«˜è´¨é‡çš„
    selected = high_quality_items[:limit]
    
    # å¦‚æœä¸å¤Ÿ 50 ä¸ªï¼Œä»å‰©ä¸‹çš„é‡Œé¢éšæœºè¡¥
    if len(selected) < limit:
        needed = limit - len(selected)
        if len(other_items) >= needed:
            selected.extend(random.sample(other_items, needed))
        else:
            selected.extend(other_items)
            
    # æ‰“ä¹±é¡ºåºï¼Œé˜²æ­¢åŒç±»é£æ ¼æ‰å †
    random.shuffle(selected)
    return selected[:limit]

def download_and_process_image(url, save_path):
    # (ä¿æŒåŸæœ‰çš„ä¸‹è½½é€»è¾‘ä¸å˜)
    try:
        headers = {'User-Agent': 'Mozilla/5.0...'}
        resp = requests.get(url, headers=headers, timeout=15)
        if resp.status_code == 200:
            img = Image.open(BytesIO(resp.content))
            if img.mode in ("RGBA", "P"):
                img = img.convert("RGB")
            # å‹ç¼©å°ºå¯¸å’Œè´¨é‡
            img.thumbnail((800, 800), Image.Resampling.LANCZOS)
            img.save(save_path, "WEBP", quality=75)
            return True
        return False
    except Exception:
        return False

def main():
    ensure_dir(OUTPUT_DIR)
    
    # 1. Fetch
    items = fetch_data()
    if not items: return

    # 2. Smart Select (ä»£æ›¿åŸæ¥çš„ random)
    selected_items = smart_select_items(items, SAMPLE_SIZE)
    print(f"Selected {len(selected_items)} items for processing.")
    
    final_data = []
    
    # 3. Process
    for index, item in enumerate(selected_items):
        item_id = item.get("id", index)
        
        # è·å–å›¾ç‰‡è·¯å¾„
        image_path = item.get("coverImage") or (item.get("images")[0] if item.get("images") else None)
        if not image_path: continue
            
        # è·å–æç¤ºè¯
        prompts = item.get("prompts", [])
        prompt_text = prompts[0] if prompts else "ai art"
        
        # --- å…³é”®ä¿®æ”¹ï¼šç”Ÿæˆ SEO æ–‡ä»¶å ---
        seo_name = clean_filename(prompt_text if isinstance(prompt_text, str) else "ai-art")
        # åŠ ä¸Š index é˜²æ­¢é‡å
        local_filename = f"{seo_name}-{index}.webp"
        # -----------------------------
        
        full_img_url = BASE_IMG_URL + image_path
        local_path = os.path.join(OUTPUT_DIR, local_filename)
        
        print(f"[{index+1}/{SAMPLE_SIZE}] Downloading: {local_filename}...")
        
        if download_and_process_image(full_img_url, local_path):
            final_data.append({
                "id": item_id,
                # å‰ç«¯ç”¨ç›¸å¯¹è·¯å¾„
                "img": f"assets/images/{local_filename}",
                "prompt": prompt_text
            })
            time.sleep(0.1)
    
    # 4. Save JS
    js_content = f"window.SAMPLE_DATA = {json.dumps(final_data, indent=2, ensure_ascii=False)};"
    with open(DATA_JS_PATH, "w", encoding="utf-8") as f:
        f.write(js_content)
        
    print(f"Done! SEO-friendly assets generated in {DATA_JS_PATH}")

if __name__ == "__main__":
    main()